{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup, SoupStrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import pickle\n",
    "PICKLE_FILEPATHS = {'overview':'overview_htmls.pkl', 'player':'player_htmls.pkl'}\n",
    "\n",
    "def get_almost_constants():\n",
    "    with open('almost_constants.json', 'r') as f:\n",
    "        almost_constants = json.load(f)\n",
    "    return almost_constants\n",
    "\n",
    "async def fetch(session, url):\n",
    "    with aiohttp.Timeout(30):\n",
    "        async with session.get(url) as response:\n",
    "            return await response.text()\n",
    "\n",
    "async def fetch_all(session, urls, loop):\n",
    "    results = await asyncio.gather(\n",
    "        *[fetch(session, url) for url in urls],\n",
    "        return_exceptions=True  # so we can deal with exceptions later\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_htmls_from_pickle(file_key):\n",
    "    with open(PICKLE_FILEPATHS[file_key], 'rb') as f:\n",
    "        htmls = pickle.load(f)\n",
    "    return htmls\n",
    "\n",
    "def save_htmls_to_pickle(htmls, file_key):\n",
    "    with open(PICKLE_FILEPATHS[file_key], 'wb') as f:\n",
    "        pickle.dump(overview_htmls, f)\n",
    "    \n",
    "\n",
    "def get_htmls(urls, from_file=False, file_key=None):\n",
    "    if from_file:\n",
    "        return get_htmls_from_pickle(file_key)\n",
    "    else:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        with aiohttp.ClientSession(loop=loop) as session:\n",
    "            htmls = loop.run_until_complete(fetch_all(session, urls, loop))\n",
    "    return dict(zip(urls, htmls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_overview_urls():\n",
    "    urls = []\n",
    "    base_url = \"https://sofifa.com/players?offset=\"\n",
    "    offset_increment = 80\n",
    "    for i in range(226): # WARNING: this may not be invariant\n",
    "        url = base_url + str(i * offset_increment)\n",
    "        urls.append(url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_player_urls(IDs):\n",
    "    urls = []\n",
    "    base_url = 'https://sofifa.com/player/'\n",
    "    for ID in IDs:\n",
    "        url = base_url + str(ID)\n",
    "        urls.append(url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_player_htmls(IDs, from_file=False):\n",
    "    urls = get_player_urls(IDs)\n",
    "    return get_htmls(urls, from_file, file_key='player')\n",
    "\n",
    "def id_from_url(url):\n",
    "    return url.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_overview_htmls(from_file=False):\n",
    "    urls = get_overview_urls()\n",
    "    return get_htmls(urls, from_file, file_key='overview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%time overview_htmls = get_htmls(get_overview_urls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_htmls_to_pickle(overview_htmls, 'overview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_single_row(overview_table_row):\n",
    "    \n",
    "    record_dict = {}\n",
    "    td = overview_table_row.find_all('td')\n",
    "    record_dict['photo'] = td[0].find('img').get('data-src')\n",
    "    record_dict['ID'] = td[0].find('img').get('id')\n",
    "    record_dict['nationality'] = td[1].find('a').get('title')\n",
    "    record_dict['flag'] = td[1].find('img').get('data-src')\n",
    "    record_dict['name'] = td[1].find_all('a')[1].text\n",
    "    record_dict['age'] = td[2].find('div').text.strip()\n",
    "    record_dict['overall'] = td[3].text.strip()\n",
    "    record_dict['potential'] = td[4].text.strip()\n",
    "    record_dict['club'] = td[5].find('a').text\n",
    "    record_dict['club_logo'] = td[5].find('img').get('data-src')\n",
    "    record_dict['value'] = td[7].text\n",
    "    record_dict['wage'] = td[8].text\n",
    "    record_dict['special'] = td[17].text\n",
    "    \n",
    "    return record_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_single_overview_page(html, strainer):\n",
    "    soup = BeautifulSoup(html, 'lxml', parse_only=strainer)\n",
    "    row_dicts = []\n",
    "    for row in soup.find_all('tr'):\n",
    "        row_dicts.append(parse_single_row(row))\n",
    "    return row_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_overview_data(overview_htmls):\n",
    "    strainer = SoupStrainer('tbody')\n",
    "    data = []\n",
    "    for html in overview_htmls:\n",
    "        row_dicts = parse_single_overview_page(html, strainer)\n",
    "        data.extend(row_dicts)\n",
    "    return pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# doesn't work in notebook but should work otherwise\n",
    "# import multiprocessing as mp\n",
    "# num_workers = mp.cpu_count()\n",
    "# pool = mp.Pool(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# def square(x):\n",
    "#     return x**2\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     pool.map(square, [1,3,5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# x = pool.map(parse_single_overview_page, overview_htmls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_currency(curr_col):\n",
    "    without_euro_symbol = curr_col.str[1:]\n",
    "    unit_symbol = without_euro_symbol.str[-1]\n",
    "    numeric_part = np.where(unit_symbol == '0', 0, without_euro_symbol.str[:-1].pipe(pd.to_numeric))\n",
    "    multipliers = unit_symbol.replace({'M':1e6, 'K':1e3}).pipe(pd.to_numeric)\n",
    "    return numeric_part * multipliers\n",
    "\n",
    "def clean_overview_data(df):\n",
    "    return (df.assign(EUR_value = lambda df: df['value'].pipe(convert_currency), \n",
    "                                EUR_wage = lambda df: df['wage'].pipe(convert_currency))\n",
    "            .drop(['value', 'wage'], axis=1))\n",
    "\n",
    "#player_personal_data = df.pipe(clean_personal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_overview_data(from_file=False):\n",
    "    overview_htmls = get_overview_htmls()\n",
    "    return parse_overview_data(overview_htmls).pipe(clean_overview_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_overview_data = get_overview_data(from_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#player_personal_data.to_csv('Complete/PlayerPersonalData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def headline_attribute_from_line(line):\n",
    "    equals_sign_loc = line.find('=')\n",
    "    attribute_name = line[equals_sign_loc - 4: equals_sign_loc - 1].lower()\n",
    "    attribute_value = int(line[equals_sign_loc+2:equals_sign_loc+4])\n",
    "    return {'name':attribute_name, 'value':attribute_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def standardise_spelling(player_attribute_name):\n",
    "#     return player_attribute_name.lower().replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardise_spelling(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player_data_url = 'https://sofifa.com/player/20801'\n",
    "# skill_names = ['ID', 'crossing', 'finishing', 'heading_accuracy','short_passing', 'volleys', 'dribbling', 'curve',\n",
    "#                'free_kick_accuracy', 'long_passing', 'ball_control', 'acceleration', 'sprint_speed', 'agility',\n",
    "#                'reactions', 'balance', 'shot_power', 'jumping', 'stamina', 'strength', 'long_shots', 'aggression',\n",
    "#                'interceptions', 'positioning', 'vision', 'penalties', 'composure', 'marking', 'standing_tackle',\n",
    "#                'sliding_tackle', 'gk_diving', 'gk_handling', 'gk_kicking', 'gk_positioning', 'gk_reflexes']\n",
    "# headline_attribute_names = ['PAC', 'SHO', 'PAS', 'DRI', 'DEF', 'PHY']\n",
    "# all_attribute_names = skill_names + headline_attribute_names\n",
    "player_attribute_dict = {'ID': 20801}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_code = requests.get(player_data_url)\n",
    "gk_source_code = requests.get('https://sofifa.com/player/228736')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 65.5 ms\n"
     ]
    }
   ],
   "source": [
    "plain_text = source_code.text\n",
    "strainer = SoupStrainer(['section', 'script'])\n",
    "soup = BeautifulSoup(plain_text, 'lxml', parse_only=strainer)\n",
    "gk_soup = BeautifulSoup(gk_source_code.text, 'lxml', parse_only=strainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _parse_col3_divs(soup):\n",
    "    col_divs = (soup.find('section', class_='container', recursive=False)\n",
    "                .section\n",
    "                .article\n",
    "                .find_all('div', class_='columns', recursive=False))\n",
    "    col3_divs = []\n",
    "    for sub_div in col_divs:\n",
    "        col3_divs.extend(sub_div.find_all('div', class_='col-3', recursive=False))\n",
    "    return col3_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['78', '+4', 'Penalties']"
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(messi_col3_divs[4].div.ul.find_all('li', recursive=False)[4].stripped_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_main_attributes(col3_divs):\n",
    "    attribute_dict = {}\n",
    "    for sub_div in col3_divs[:-1]: # last one is traits and specialities\n",
    "        for li in sub_div.div.ul.find_all('li', recursive=False):\n",
    "            stripped_strings = list(li.stripped_strings)\n",
    "            attribute_name = stripped_strings[-1]\n",
    "            attribute_value = stripped_strings[0]\n",
    "            attribute_dict[attribute_name] = attribute_value\n",
    "    return attribute_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col3_divs = _parse_col3_divs(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 499 µs\n"
     ]
    }
   ],
   "source": [
    "%time x = parse_main_attributes(col3_divs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "headline attributes like PHY: seems to be related to Ultimate Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_headline_attributes(soup):\n",
    "    attribute_dict = {}\n",
    "    headline_attribute_script = soup.find_all('script')[1]\n",
    "    for line in headline_attribute_script.text.split('\\r\\n'):\n",
    "        if 'point' in line:\n",
    "            attr_subdict = headline_attribute_from_line(line)\n",
    "            attribute_dict[attr_subdict['name']] = attr_subdict['value']\n",
    "    return attribute_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meta section at top of player page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_player_metadata(soup):\n",
    "    \n",
    "    attribute_dict = {}\n",
    "    player_info_html = soup.find('div', class_='meta').find('span')\n",
    "    # nationality, age and flag were found in player overview\n",
    "    attribute_dict['preferred_positions'] = [span.text for span in player_info_html.find_all('span')]\n",
    "    age_height_weight = player_info_html.contents[-1].split()\n",
    "    attribute_dict['Birth date'] = ' '.join(age_height_weight[2:5]).replace(',', '').strip('(').strip(')')\n",
    "    attribute_dict['Height_cm'] = age_height_weight[5].strip('cm')\n",
    "    attribute_dict['Weight_kg'] = age_height_weight[-1].strip('kg')\n",
    "    \n",
    "    return attribute_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_uls = soup.find_all('ul', class_='pl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _standardise_ul(ul):\n",
    "    return list(standardise_spelling(item) for item in ul.stripped_strings)\n",
    "\n",
    "def _get_traits_and_specialities_dict(player_traits, player_specialities, all_traits, all_specialities):\n",
    "    trait_dict = {trait: (trait in player_traits) for trait in all_traits}\n",
    "    speciality_dict = {speciality: (speciality in specialities) for speciality in all_specialities}\n",
    "    return {**trait_dict, **speciality_dict}\n",
    "\n",
    "def parse_traits_and_specialities(col3_divs, all_traits, all_specialities):\n",
    "    uls = col3_divs[-1].div.find_all('ul', recursive=False)\n",
    "    player_traits = _standardise_ul(uls[0])\n",
    "    player_specialities = _standardise_ul(page_uls[1])\n",
    "    result = _get_traits_and_specialities_dict(player_traits, player_specialities, all_traits, all_specialities)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_player_miscellaneous_data(page_uls):\n",
    "    data = page_uls[0]\n",
    "    attribute_dict = {}\n",
    "    strings = data.stripped_strings\n",
    "    for key in strings:\n",
    "        attribute_dict[standardise_spelling(key)] = next(strings)\n",
    "    work_rates = attribute_dict.pop('Work rate').split(' / ')\n",
    "    attribute_dict['Work rate att'] = work_rates[0]\n",
    "    attribute_dict['work rate def'] = work_rates[1]\n",
    "    return attribute_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_position_ratings(soup, all_positions):\n",
    "    position_col_name = 'Position'\n",
    "    ratings_table = soup.find('table', class_='table table-hover')\n",
    "    if ratings_table:\n",
    "        position_ratings_df = (pd.read_html(str(ratings_table))[0][[position_col_name, 'OVA']]\n",
    "                        .rename(columns=standardise_spelling))\n",
    "        split_df = (position_ratings_df[position_col_name]\n",
    "                    .str.split(expand=True)\n",
    "                    .assign(ova=p['ova']))\n",
    "        position_ratings_dict = (pd.concat(split_df[[i, 'ova']].rename(columns={i:position_col_name}) for i in range(3))\n",
    "                                 .dropna()\n",
    "                                 .set_index(position_col_name)\n",
    "                                 .to_dict()['ova'])\n",
    "        position_ratings_dict.update({'GK':np.nan})\n",
    "    else:\n",
    "        gk_rating = soup.find('div', class_='stats').td.span.text\n",
    "        position_ratings_dict = {'GK':gk_rating, **{pos:np.nan for pos in all_positions}}\n",
    "    return position_ratings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this isn't actually any better than hard-coding as these positions are invariant\n",
    "# def get_unique_positions(position_ratings):\n",
    "#     return position_ratings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put in separate script\n",
    "# def get_all_traits_and_specialities():\n",
    "#     url = 'https://sofifa.com/players/top'\n",
    "#     html = requests.get(url).text\n",
    "#     strainer = SoupStrainer('form', action='/players', class_='pjax relative')\n",
    "#     soup = BeautifulSoup(html, 'lxml', parse_only=strainer)\n",
    "#     traits1 = list(standardise_spelling(item) for item in traits_soup.find(attrs={'name':'t1[]'}).stripped_strings)\n",
    "#     traits2 = list(standardise_spelling(item) for item in traits_soup.find(attrs={'name':'t2[]'}).stripped_strings)\n",
    "#     all_traits = [*traits1, *traits2]\n",
    "#     all_specialities = list(standardise_spelling(item) for item in traits_soup.find(attrs={'name':'sc[]'}).stripped_strings)\n",
    "#     return {'traits':all_traits, 'specialities':all_specialities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x = get_all_traits_and_specialities()\n",
    "\n",
    "# import json\n",
    "# almost_constants = {**x, 'positions':unique_positions}\n",
    "# with open('almost_constants.json', 'w') as f:\n",
    "#     json.dump(almost_constants, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_full_position_preferences(preferred_positions_list, all_positions):\n",
    "    return {'prefers_' + pos: (pos in preferred_positions_list) for pos in all_positions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_single_player_page(html, strainer, almost_constants):\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'lxml', parse_only=strainer)\n",
    "    all_traits = almost_constants['traits']\n",
    "    all_specialities = almost_constants['specialities']\n",
    "    all_positions = almost_constants['positions']\n",
    "    \n",
    "    col3_divs = _parse_col3_divs(soup)\n",
    "    main_attributes = parse_main_attributes(col3_divs)\n",
    "    headline_attributes = parse_headline_attributes(soup)\n",
    "    metadata = parse_player_metadata(soup)\n",
    "    _preferred_positions = metadata.pop('preferred_positions')\n",
    "    _page_uls = soup.find_all('ul', class_='pl')\n",
    "    traits_and_specialities = parse_traits_and_specialities(col3_divs, all_traits, all_specialities)\n",
    "    miscellaneous_data = parse_player_miscellaneous_data(_page_uls)\n",
    "    position_ratings = get_position_ratings(soup, all_positions)\n",
    "    position_preferences = get_full_position_preferences(_preferred_positions, all_positions)\n",
    "    return {**main_attributes, **headline_attributes, **metadata, \n",
    "            **traits_and_specialities, **miscellaneous_data, **position_ratings,\n",
    "           **position_preferences}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_player_detailed_data(player_htmls, almost_constants):\n",
    "    strainer = SoupStrainer(['section', 'script'])\n",
    "    data = []\n",
    "    for player_id, html in player_htmls.items():\n",
    "        row_dict = parse_single_player_page(html, strainer, almost_constants)\n",
    "        row_dict['ID'] = id_from_url(player_id)\n",
    "        data.append(row_dict)\n",
    "    return pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_player_detailed_data(IDs, from_file=False):\n",
    "    almost_constants = get_almost_constants()\n",
    "    player_htmls = get_player_htmls(IDs, from_file)\n",
    "    return parse_player_detailed_data(player_soups, almost_constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun -s \"cumulative\" z = parse_single_player_page(soup, almost_constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.5 ms\n"
     ]
    }
   ],
   "source": [
    "%time z = parse_single_player_page(soup, almost_constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_IDs = player_overview_data['ID'].head(10)\n",
    "player_htmls = get_player_htmls(test_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = parse_player_detailed_data(player_htmls, almost_constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'work rate att'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Kevin\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2441\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2442\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5280)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5126)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20523)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20477)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'work rate att'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-893-4fc450d54dbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'work rate att'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Kevin\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1964\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kevin\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1970\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1971\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kevin\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1645\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kevin\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kevin\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2442\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2444\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5280)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5126)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20523)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20477)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'work rate att'"
     ]
    }
   ],
   "source": [
    "x['work rate att']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi_html = player_htmls['https://sofifa.com/player/158023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi_strainer = SoupStrainer(['section', 'script'])\n",
    "messi_soup = BeautifulSoup(messi_html, 'lxml', parse_only=messi_strainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messi_page_uls = messi_soup.find_all('ul', class_='pl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Body type': 'Messi',\n",
       " 'International reputation': '5',\n",
       " 'Preferred foot': 'Left',\n",
       " 'Real face': 'Yes',\n",
       " 'Release clause': '€215.3M',\n",
       " 'Skill moves': '4',\n",
       " 'Weak foot': '4',\n",
       " 'Work rate att': 'Medium',\n",
       " 'work rate def': 'Medium'}"
      ]
     },
     "execution_count": 898,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_player_miscellaneous_data(messi_page_uls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'+4': '78',\n",
       " '96': 'Penalties',\n",
       " 'Acceleration': '92',\n",
       " 'Aggression': '48',\n",
       " 'Agility': '90',\n",
       " 'Balance': '95',\n",
       " 'Ball control': '95',\n",
       " 'Crossing': '77',\n",
       " 'Curve': '89',\n",
       " 'Dribbling': '97',\n",
       " 'Finishing': '95',\n",
       " 'Free kick accuracy': '90',\n",
       " 'GK diving': '6',\n",
       " 'GK handling': '11',\n",
       " 'GK kicking': '15',\n",
       " 'GK positioning': '14',\n",
       " 'GK reflexes': '8',\n",
       " 'Heading accuracy': '71',\n",
       " 'Interceptions': '22',\n",
       " 'Jumping': '68',\n",
       " 'Long passing': '87',\n",
       " 'Long shots': '88',\n",
       " 'Marking': '13',\n",
       " 'Positioning': '93',\n",
       " 'Reactions': '95',\n",
       " 'Short passing': '88',\n",
       " 'Shot power': '85',\n",
       " 'Sliding tackle': '26',\n",
       " 'Sprint speed': '87',\n",
       " 'Stamina': '73',\n",
       " 'Standing tackle': '28',\n",
       " 'Strength': '59',\n",
       " 'Vision': '90',\n",
       " 'Volleys': '85'}"
      ]
     },
     "execution_count": 878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messi_col3_divs = _parse_col3_divs(messi_soup)\n",
    "parse_main_attributes(messi_col3_divs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['78', '+4', 'Penalties']"
      ]
     },
     "execution_count": 888,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(messi_col3_divs[4].div.ul.find_all('li', recursive=False)[4].stripped_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "col3_divs = _parse_col3_divs(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ul class=\"pl mb-20\">\n",
       " <li>Power free kick</li>\n",
       " <li>Flair</li>\n",
       " <li>Long shot taker</li>\n",
       " <li>Skilled dribbling</li>\n",
       " </ul>, <ul class=\"pl\">\n",
       " <li>Speedster</li>\n",
       " <li>Dribbler</li>\n",
       " <li>Distance shooter</li>\n",
       " <li>Acrobat</li>\n",
       " <li>Clinical finisher</li>\n",
       " <li>Complete forward</li>\n",
       " </ul>]"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col3_divs[-1].div.find_all('ul', recursive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(from_file):\n",
    "    # download overview htmls. Parse these into a dataframe and save this into a variable.\n",
    "    # Use the df's ID column to get urls for player personal data.\n",
    "    # for the first player url only, use the position ratings table to get a sequence of unique positions, and save this as a variable\n",
    "    # actually just hard code it\n",
    "    player_overview_data = get_overview_data(from_file)\n",
    "    IDs = player_overview_data['ID']\n",
    "    player_detailed_data = get_player_detailed_data(IDs, from_file)\n",
    "    merged = player_overview_data.merge(player_detailed_data, on='ID')\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data.to_csv('Allplayer.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_data.to_csv('Complete/PlayerAttributeData.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data.to_csv('Complete/Dataset.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data.drop('Unnamed: 0', 1,  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data.drop('ID_x', 1,  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data['ID_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = full_data.rename(index=str, columns={\"ID_y\": \"ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.to_csv('Complete/Dataset.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heights = ['1cm' for i in range(1000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 694 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s = pd.Series(heights)\n",
    "s2 = s.str.strip('cm').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 453 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "heights2 = [item.strip('cm') for item in heights]\n",
    "s2 = pd.Series(heights2).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".strip method is faster on individual strings in a loop than in pandas Series, for some reason. Type conversion from str to int is still faster with Series."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
